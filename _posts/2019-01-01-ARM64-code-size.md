---
layout: post
title: ARM64 code size
subtitle: TODO
tags: [arm64, performance, assembly, work]
comments: true
---

This is the 5th of the blog posts series that talks about ARM64 performance investigation for .NET 5. You can read previous blogs at:
*  [Part 1 - ARM64 performance of .Net Core](..\2020-06-30-Dotnet-Arm64-Performance)
*  [Part 2 - Memory barriers in ARM64](..\2020-07-02-ARM64-Memory-Barriers)
*  [Part 3 - Peephole optimizations in ARM64](..\2020-07-05-ARM64-peephole-optimizations)
*  [Part 4 - Two mystic ARM64 instructions](..\2019-01-01-Two-mystic-ARM64-instructions)

In this post, I will talk about the generated code size differences that I noticed between x64 and ARM64 and what I learned from it. 

### Code size ratio of ARM64 / x64

The analysis mentioned in this blog was done by running [crossgen tool](https://github.com/dotnet/coreclr/blob/master/Documentation/building/crossgen.md) on all .NET framework libraries and saving the JIT code generated for those libraries. The JIT code was generated by setting environment variable `COMPlus_NgenDisasm=*` for both x64 and ARM64. To my surprise, the code size ratio of ARM64 / x64 was approxiametely **1.75**. That was a huge difference and a hard task for me to figure out why that is the case. There are 1000s of methods in .NET framework libraries and it is extremely difficult and nearly impossible to compare x64 vs. ARM64 generated code of every method and do the analysis. Additionally, the generated file containing JIT code of all those methods was `900MB` long.

I broke down the problem in pieces and decided to start investigating the methods having smaller x64 JIT code size but bigger ratio compared to ARM64 JIT code size. For example, imagine 2 methods `A` and `B` with following code size.

| Method Name | ARM64 code size | x64 code size | Ratio |
|-------------|-----------------|---------------|-------|
| A           | 5000 bytes      | 1000 bytes    | 5     |
| B           | 400 bytes       | 100 bytes     | 4     |

I decided to start investigating `B` although the ratio was lesser than that of `A`. However the analysis time needed for method `B` will be far lesser than that needed for `A` because there are fewer instructions in `B` to look and compare against x64.


### Code size analysis result

Below I will highlight some of the key factors that contributed to bigger size of ARM64 generated code.

#### RISC vs. CISC


Since ARM64 has an ISA with fixed 32-bit instruction width, the move instructions have space for 16-bit unsigned immediate. To move bigger immediate value, we need to move the value in multiple steps using chunks of 16-bits (`movz/movk`). Due to this, multiple `mov` instructions are generated to load a single bigger value in register in contrast to x64 where a single `mov` can load bigger immediate.

I wanted to see if it has been already evaluated or if it is feasible to store such immediate values in a literal pool and load the values from the pool using `ldr` instead of moving using multi-step `movz/movk`. I know this would involve accessing memory instead and might end up being slower. In fact, the examples I have tried on clang/gcc, they use `movz/movk` mostly.

I have also noticed cases where we try to move 2 immediates back to back that are just bytes apart from each other. E.g. Below is the code generated for [Vector4.Add(Vector4, Vector4)](https://docs.microsoft.com/en-us/dotnet/api/system.numerics.vector4.add?view=netframework-4.8#System_Numerics_Vector4_Add_System_Numerics_Vector4_System_Numerics_Vector4_) method where it tries to load the parameters before performing `fadd`. 

{% highlight asm linenos %}
D29D9900          movz    x0, #0xecc8
F2A785E0          movk    x0, #0x3c2f LSL #16
F2C051C0          movk    x0, #654 LSL #32
F9400000          ldr     x0, [x0]            ; <==== loads from address 0x6543c2fecc8
FD400410          ldr     d16, [x0,#8]
D29D9800          movz    x0, #0xecc0
F2A785E0          movk    x0, #0x3c2f LSL #16
F2C051C0          movk    x0, #654 LSL #32    ; <==== loads from address 0x6543c2fecc0
F9400000          ldr     x0, [x0]
FD400411          ldr     d17, [x0,#8]
0E31D610          fadd    v16.2s, v16.2s, v17.2s
{% endhighlight %}

The 2nd set of move instructions can be optimized by doing `sub x0, x0, 8`.

Just to get the stats to see how often we need to generate higher immediate values, I ran `crossgen` tool on all (or most) of the libraries and dumped the assembly code produced from it for ARM64. Then I extracted out the methods and the portion of code that uses `movz/movk` pair to load the immediates. There were total 191028 methods crossgened out of which 4578 methods contained pair of movz/movk. In all there were 11856 groups of movz/movk instructions.
You can see the summary in [movs.txt](https://github.com/dotnet/runtime/files/4453526/movs.txt).

Some of the questions I am thinking about on seeing the above results:
1. Some of the `Utf8Parser` methods loads constant multiple times and can it be optimized to reuse the value?
2. Is it possible to re-evaluate constant propagation for certain scenarios where the value of constant is big and since it gets propagated, we end up creating these mov sequence multiple times?
3. Should we tweak our inline heuristics because of the amount of code generated for ARM64 is more than that for Intel?
4. Can we eliminate some of the `movz/movk` by doing arithmetic manipulation, the way I mentioned in above example?
5. And finally, is it beneficial to use literal pool table for certain scenarios?

References:
- https://dinfuehr.github.io/blog/encoding-of-immediate-values-on-aarch64/
- https://azeria-labs.com/memory-instructions-load-and-store-part-4/
- http://www.keil.com/support/man/docs/armasm/armasm_dom1359731147760.htm


--------------------------
The analysis mentioned in this section was done by running crossgen tool on all framework libraries and taking the JIT dumps of them using flag "COMPlus_NgenDisasm=1" environment for both x64 and arm64. On the produced dump file, C# tool was written to find code patterns that  can give us optimization opportunities.

I looked into the assembly code of methods that were showing biggest delta in terms of code size and no. of instructions. Here is the summary of my findings so far. There might be more reasons and I will open relevant issues for them.

	1. Crossgen generated indirect calls for method calls. The code generated for x64 just have 1 instruction "call [indirect_method]" and takes 6 bytes. However for arm64, we generate series of 6 instructions to go through the indirection cell. These instructions take 24 bytes. There exist an opportunity to optimize arm64 side as Bruce pointed out  in #35108(comment). If we optimize it, that alone can bring down the total size of ARM64 code for framework libraries by 10%.
	
	2. There was code produced by crossgen for lot of empty constructors. During runtime, this code might get inlined, but for the analysis, I was aggregating the code produced for such methods. Interestingly, x64 code for such methods just had 1 instruction "ret" (1 byte size) while arm64 had prolog/epilog with empty body. Bruce explained me that prodmlog/epilog is needed so "return address hijacking" for GC should work for arm64. So such methods comprised of 16 bytes. There were also many methods for which x64 was able to get away without prolog/epilog. The contribution of such methods to the code size difference were significant. See #35274.
	
	3. Lot of methods have redundant code related to struct passing and returning. Carol's multi-reg return work will fix it. See e.g. of redundant code in #35071.
	
	4. Constants/address creation movz/movk instructions are present in many places I have seen. We don't completely CSE them resulting in increasing the code size. See below examples of such code
		○ #34732(comment)
		○ #34732(comment)
	
	5. If we take advantage of post index addressing mode, we can potentially reduce the code size from 20 bytes to 8 bytes. See example in #34810 and #35618.

	6. I have opened several issues that if fixed using peep-hole style optimization will reduce the size and we can get some speed-up.
		○ #35130
		○ #35132
		○ #35133
		○ #35134
		○ #35136
		○ #35141
		○ #35252
		○ #35254
		○ #35613
		○ #35614

x64 being variable encoding as opposed to arm64 which has fixed encoding, for many methods, the code size of x64 was way smaller despite having same or less no. of instructions than arm64. So I am not sure if just looking at the code size would be right way to judge the size difference. To keep things even, I started comparing instructions count difference between x64 vs. arm64. However, I don't think it is worthwhile sharing the instruction count difference that I got out of dump I produced by running crossgen.  I have seen that many methods in the dump are repeated (possibly because they are referenced in various assemblies). But one thing that could be worth comparing is R2R image size difference between the two and see where we stand as compared to what C++ team produce.

(Some of the information might be repeated elsewhere, but I just wanted to capture all the code size impacting studies I have done in one place). 